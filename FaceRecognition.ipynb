{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c040a0-37fe-436e-853b-22b01634e373",
   "metadata": {},
   "source": [
    "## Face Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cc38e-64ac-4749-97f1-4025450d844a",
   "metadata": {},
   "source": [
    "### Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fa264-e418-4130-80ad-c4cd9eb804b0",
   "metadata": {},
   "source": [
    "This project is about recognizing whether the person in the input image is exited in my Photo database. The idea comes from a Face Recognition task for employees' access by using their photo IDs to the company. Here are two tasks in my basic CNN project.\n",
    "\n",
    "1. Require a user to input an image\n",
    "2. Task1: Detecte whether the input image is about human faces\n",
    "3. Task2: Finger whether the person in the input image is exited in my photo database\n",
    "4. Task2 only is executed when task1 returns True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1acac-e116-45a7-85b1-10d6533b0525",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de473ab9-fe69-4250-a5e0-2102d034c531",
   "metadata": {},
   "source": [
    "Human Face Detection: The HumanFaceDetector class uses a pre-trained model to detect human faces in the input image. The process_face_recognition function checks if the image contains a human face and returns a message accordingly.\n",
    "\n",
    "Image Similarity Check: The ImageSimilarityCNN class reads all images in a local folder, converts them into vectors, and performs similarity analysis with the input image.\n",
    "\n",
    "Main Function: The main function first checks if the input image contains a human face. If it does, it proceeds to perform the similarity analysis. If not, it prints \"It is not a human face image\" and exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93160ff6-2809-4388-8c7a-b093f1843a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from transformers import AutoFeatureExtractor, AutoModelForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff5e6e8-47f5-42cd-969f-c7231b06c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Task: Human Face Detection\n",
    "class HumanFaceDetector:\n",
    "    def __init__(self):\n",
    "        model_name = \"facebook/detr-resnet-50\"\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "        self.model = AutoModelForObjectDetection.from_pretrained(model_name)\n",
    "    \n",
    "    def detect_human_face(self, image_path):\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Error: Image file {image_path} does not exist.\")\n",
    "            return False, None\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        inputs = self.feature_extractor(images=img_rgb, return_tensors=\"pt\")\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        target_sizes = torch.tensor([img.shape[:2]])\n",
    "        results = self.feature_extractor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]\n",
    "        \n",
    "        for score, label in zip(results[\"scores\"], results[\"labels\"]):\n",
    "            if (self.model.config.id2label[label.item()] == 'person' and score > 0.7):\n",
    "                return True, img\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "def process_face_recognition(image_path):\n",
    "    face_detector = HumanFaceDetector()\n",
    "    is_human, detected_image = face_detector.detect_human_face(image_path)\n",
    "    \n",
    "    if not is_human:\n",
    "        return \"It is not a human face image\"\n",
    "    \n",
    "    return \"Human face detected!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef149541-d219-4382-bc95-a2c6057d0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Task: Image Similarity Check\n",
    "class ImageSimilarityCNN:\n",
    "    def __init__(self, image_directory):\n",
    "        self.image_directory = image_directory\n",
    "        self.model = self.build_model()\n",
    "        self.image_vectors = self.load_images()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        image = Image.open(image_path).convert('RGB')  # Convert image to RGB\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "\n",
    "    def load_images(self):\n",
    "        image_vectors = []\n",
    "        for filename in os.listdir(self.image_directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(self.image_directory, filename)\n",
    "                image_array = self.preprocess_image(image_path)\n",
    "                image_vector = self.model.predict(image_array)\n",
    "                image_vectors.append(image_vector.flatten())\n",
    "        return image_vectors\n",
    "\n",
    "    def is_similar(self, input_image_path):\n",
    "        input_image_array = self.preprocess_image(input_image_path)\n",
    "        input_image_vector = self.model.predict(input_image_array).flatten()\n",
    "        for image_vector in self.image_vectors:\n",
    "            similarity = np.dot(input_image_vector, image_vector) / (np.linalg.norm(input_image_vector) * np.linalg.norm(image_vector))\n",
    "            if similarity > 0.7:  # Threshold for similarity\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4debc-19e8-4ed2-bf7e-faa93fb95ff1",
   "metadata": {},
   "source": [
    "Here, I also try to compare the performances of ResNet50 and InceptionV3 models with optimizations to prevent overfitting issues. I found somethings very interesting. \n",
    "\n",
    "1. InceptionV3 computed faster to get the output as it is a parallel computing architecture framework.\n",
    "2. ResNet50 seems to get more details to set a lower similarity value than other models since it can learn very deep layers by skipping one hidden layer in each step.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe9b32-149a-41d0-acea-7cd7a65a1585",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "Data Augmentation: The ImageDataGenerator is used to apply random transformations to the images, such as rotation, width/height shift, shear, zoom, and horizontal flip. This helps in generating variations of the training images to prevent overfitting.\n",
    "Loading Images with Augmentation: The load_images method now uses the ImageDataGenerator to augment each image before converting it to a vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59307e61-d8ae-4330-8c45-df7aa2b7dc00",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ada76647-c126-44cb-a8ad-a9e5563a93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5f91549-25ce-4088-90d8-038cd1ba52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Task: Image Similarity Check with ResNet-50 and Data Augmentation\n",
    "class ImageSimilarityResNet50:\n",
    "    def __init__(self, image_directory):\n",
    "        self.image_directory = image_directory\n",
    "        self.model = self.build_model()\n",
    "        self.image_vectors = self.load_images()\n",
    "\n",
    "    def build_model(self):\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)  # Add dropout to prevent overfitting\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=x)\n",
    "        return model\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        image = Image.open(image_path).convert('RGB')  # Convert image to RGB\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "\n",
    "    def load_images(self):\n",
    "        image_vectors = []\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        for filename in os.listdir(self.image_directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(self.image_directory, filename)\n",
    "                image_array = self.preprocess_image(image_path)\n",
    "                for batch in datagen.flow(image_array, batch_size=1):\n",
    "                    image_vector = self.model.predict(batch)\n",
    "                    image_vectors.append(image_vector.flatten())\n",
    "                    break  # We only need one augmented image per original image\n",
    "        return image_vectors\n",
    "\n",
    "    def is_similar(self, input_image_path):\n",
    "        input_image_array = self.preprocess_image(input_image_path)\n",
    "        input_image_vector = self.model.predict(input_image_array).flatten()\n",
    "        for image_vector in self.image_vectors:\n",
    "            similarity = np.dot(input_image_vector, image_vector) / (np.linalg.norm(input_image_vector) * np.linalg.norm(image_vector))\n",
    "            if similarity > 0.5:  # Threshold for similarity\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1cbbc-8273-41bc-917b-306049cf2b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91bd2242-f93d-4079-84f5-ba5270c9414c",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef5822aa-4148-4946-8865-8bdd1baec9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10be1c03-eac5-4d7d-a009-5f742ef38785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Task: Image Similarity Check with InceptionV3 and Data Augmentation\n",
    "class ImageSimilarityInceptionV3:\n",
    "    def __init__(self, image_directory):\n",
    "        self.image_directory = image_directory\n",
    "        self.model = self.build_model()\n",
    "        self.image_vectors = self.load_images()\n",
    "\n",
    "    def build_model(self):\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)  # Add dropout to prevent overfitting\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=x)\n",
    "        return model\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        image = Image.open(image_path).convert('RGB')  # Convert image to RGB\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "\n",
    "    def load_images(self):\n",
    "        image_vectors = []\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        for filename in os.listdir(self.image_directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(self.image_directory, filename)\n",
    "                image_array = self.preprocess_image(image_path)\n",
    "                for batch in datagen.flow(image_array, batch_size=1):\n",
    "                    image_vector = self.model.predict(batch)\n",
    "                    image_vectors.append(image_vector.flatten())\n",
    "                    break  # We only need one augmented image per original image\n",
    "        return image_vectors\n",
    "\n",
    "    def is_similar(self, input_image_path):\n",
    "        input_image_array = self.preprocess_image(input_image_path)\n",
    "        input_image_vector = self.model.predict(input_image_array).flatten()\n",
    "        for image_vector in self.image_vectors:\n",
    "            similarity = np.dot(input_image_vector, image_vector) / (np.linalg.norm(input_image_vector) * np.linalg.norm(image_vector))\n",
    "            if similarity > 0.7:  # Threshold for similarity\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e1f0284-8c7d-4f14-a9b9-014a4f5410ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the input image:  test_images/test6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "true!\n",
      "ResNet50 model\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "true!\n",
      "InceptionV3 model\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "true!\n"
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "def main():\n",
    "    input_image_path = input(\"Enter the path to the input image: \")\n",
    "    \n",
    "    # First Task: Check if the image contains a human face\n",
    "    face_recognition_result = process_face_recognition(input_image_path)\n",
    "    if face_recognition_result == \"It is not a human face image\":\n",
    "        print(face_recognition_result)\n",
    "        return\n",
    "    \n",
    "    # Second Task: Perform similarity analysis if the image contains a human face\n",
    "    image_directory = 'people_images'\n",
    "\n",
    "    #model1:CNN\n",
    "    print(\"CNN model\")\n",
    "    cnn1 = ImageSimilarityCNN(image_directory)\n",
    "    if cnn1.is_similar(input_image_path):\n",
    "        print(\"true!\")\n",
    "    else:\n",
    "        print(\"false!\")    \n",
    "        \n",
    "    #model2: ResNet50\n",
    "    print(\"ResNet50 model\")\n",
    "    cnn2 = ImageSimilarityResNet50(image_directory)\n",
    "    if cnn2.is_similar(input_image_path):\n",
    "        print(\"true!\")\n",
    "    else:\n",
    "        print(\"false!\")  \n",
    "        \n",
    "    #model3: InceptionV3\n",
    "    print(\"InceptionV3 model\")\n",
    "    cnn3 = ImageSimilarityInceptionV3(image_directory)\n",
    "    if cnn3.is_similar(input_image_path):\n",
    "        print(\"true!\")\n",
    "    else:\n",
    "        print(\"false!\")      \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2084d-edae-4d05-8c65-38692afba883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
